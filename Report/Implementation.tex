\section{Implentation}
Now that we have seen the high-level design of our project we will
examine its implementation. As stated, this will consist of

\begin{itemize}
    \item A programmatic representation of our input language
    \item A compiler which will transform the above representation
          into an initial program state and series of instructions.
    \item A means of serializing this initial state into a form our
          runtime can evaluate.
    \item A runtime capable of evaluating this initial state in a
          web browser.
\end{itemize}

The compiler and language representation will be implemented in
Haskell. This is firstly because we know of existing implementations
for such a compiler written in Haskell and secondly personal 
preference. The serializer, also written in Haskell, will translate
this state into a JavaScript representation thereof. Our runtime
which will be implemented in JavaScript for reasons already explored
will provide the means to evaluate this state. 

\subsection{Core Language Representation}
We'll start with a description of the Haskell representation for
our input language, GHC's external Core. This is implemented in
Haskell using algebraic data types (or ADTs) and our own defined
types. The following the is ADT used:

\begin{verbatim}
data Expr a 
    = EVar Name
    | ENum Int
    | EConstr Int Int
    | EAp (Expr a) (Expr a)
    | ELet 
        IsRec
        [(a, Expr a)]
        (Expr a)
    | ECase
        (Expr a)
        [Alter a]
    | ELam [a] (Expr a)
    deriving(Show, Read)

    type ScDefn a = (Name, [a], Expr a)
    type CoreScDefn = ScDefn Name

    type Program a = [ScDefn a]
\end{verbatim}

\noindent We can
see many of the ideas we discussed earlier when discussing Core
and its components. The 'a's represent the type of the expression.
'Names' are just renamed strings. The EAp expression is the Core
equivalent of the function applicators we already discussed. ECase
exprs are case statements. ELet and ELam are lambda abstractions
and let expressions respectively. Supercombinators
are defined as tuples of their identifier,
the expression forming the body of the supercombinator and the 
list of parameters to pass to the expression. A program is
built from a series of these supercombinator definitions,
named ScDefn in the code. 

We will provide an example of a simple program written in this
representation. We'll use this same program as an example 
throughout this section, allowing us to see the exact steps it
takes as it moves through the stages of our compiler. The 
example we will use is the representation of a program that 
defines a supercombinator named 'K' that takes two arguments 
and returns the former applies this supercombinator to two 
integers. When written in terms of our ADT, this would look
like:

\begin{verbatim}
    [
    ("K", ["x", "y"], EVar "x"), 
    ("main", [], EAp (EAp (EVar "K")(ENum 1))(Enum 2)))
    ]
\end{verbatim}

\noindent A comparable function written in a language such
as Haskell or Miranda would look like:

\begin{verbatim}
    K x y  = x
    main = K 1 2
\end{verbatim}

\noindent Note that our
program consists of two supercombinator definitions. The first
of these is our K function. The second is a function called
"main" which applies our function K to integers 1 and 2. Our
language requires an entry point for our runtime to begin
evaluation from. In our implementation, as in many, the standard
will be to name that entry point main. It is otherwise a 
regular supercombinator definition. 

\subsection{Compiler}
Our compiler will accept an ADT representation of the core language
as input and compile this into an initial state as described below.
This state will consist of a Haskell representation of a reducible
expression graph and set of Gmachine instructions.
It is our intention that such a state can be executed from a browser
once passed to the JavaScript runtime discussed. 

We had originally intended to take the syntax of external Core itself
as the input to our compiler however 
this proved to be problematic. Tools for parsing Core exist in
previous versions of GHC but maintenance of these seems to have
stopped sometime around version 6. As the semantics of Core has
been updated since then, these tools have stagnated. It would not
be particularly difficult to write a parser for Core however the time
was not available and doing so was deemed uninteresting in the
scope of this project.

The decision to use the Gmachine as the template for our compiler
implementation will make the problem of writing the compiler
substantially easier as implementations of the Gmachine already
exist. Rather than re-implement the wheel we will re-use an 
existing implementation, specifically the one described in 
\emph{Implementing Functional Languages: A Tutorial} by Simon
Peyton Jones and David Lester. This will allow us to focus on
the more interesting aspects of the project, most specifically
the runtime. 

\subsubsection{Program State}
The following is the Haskell representation we use for our
compiled state.

\begin{verbatim}
type GmState 
= ( GmOutput,
    GmCode,
    GmStack,
    GmDump,
    GmHeap,
    GmGlobals,
    GmStats)

type GmCode = [Instruction]

type GmOutput = [Char]

type GmDump = [GmDumpItem]

type GmDumpItem = (GmCode, GmStack)     

type GmStack = [Addr]

type GmHeap = Heap Node

type Heap a = (Int, [Int], [(Int, a)])

type GmGlobals = [(Name, Addr)]

\end{verbatim}

The state of our program at any point throughout its evaluation
is represented by GmState. The definition of GmState and its
constituent components is described above. GmOutput and GmStats
were used for testing and debugging purposes and are not of great 
interest.

GmHeap is defined as Heap Node, where Heap is a parameterized type
definition and Node is the type of items contained in the heap in 
question. The Heap type itself is a three item tuple. The first item, 
an integer, represents the number of objects in the heap. The second
item, a list of integers, represents unused addresses in the heap. 
The third item is the list of Nodes contained in the heap. It is 
defined as a list of tuples of integers and 'a's. In our heap, the
'a's are nodes, as defined in GmHeap. This list of tuples is the
representation of the reducible graph described in the background
section. Nodes are defined as follows:

\begin{verbatim}
data Node 
    = NNum Int 
    | NAp Addr Addr         
    | NGlobal Int GmCode    -- NGlobal Arity Code
    | NInd Addr             -- Indirection
    | NConstr Int [Addr]
    deriving(Eq, Show)
\end{verbatim}

These correspond with the nodes described in the background section
with a couple of additions. NInd nodes are indirection nodes 
containing the address of another node in the stack. These are
used to implement the lazy updates discussed previously. When we
evaluate an expression, we create an indirection node to its
value and replace the address of this node with that of the root
of the expression. NConstr nodes are used to represent data
constructors. They consist of an Int representing the arity
of the data constructor and a list of addresses corresponding to
the locations in the heap of the elements of the data constructor.
NNum, NAp and NGlobal nodes correspond to integer primitives, 
applicators and function identifier nodes respectively. NGlobals
consist of an Int representing the arity of the supercombinator
they represent and a list of instructions describing the 
instantiation of the supercombinator.

GmStack represents our stack. It consists of a list of addrs 
which are user defined type synonyms for integers. These 
correspond to locations in the heap. GmStack is used in the same
manner as the stack described in the background section. When we
compile our input program, the stack in the initial state will
be empty. In general, addrs
of heap items needed in immediately pending expression evaluations
are pushed to the stack and removed when no longer needed.

GmGlobals is a list of tuples of names and addresses. The name
corresponds to a supercombinator definition identifier and the
address associated with it corresponds to the location in the
heap of the NGlobal node representing the supercombinator. When
we wish to find a supercombinator by name, we look up its name
in the GmGlobals array to find the address associated with it.

GmCode represents the list of instructions immediately pending
execution. An instruction describes the actions to be next
executed upon the program state. When we encounter a super-
combinator in our input language, we compile it into a list
of instructions representing its behavior. We then place an
NGlobal node containing these instructions in our heap. When
we wish to apply our supercombinator, we lookup its node by
name firstly in GmGlobals, then by address in the heap. We
then place its instructions into GmCode and execute them.
Instructions are defined as follows, we'll provide an 
explanation of their operations when discussing the implementation
of the runtime:

\begin{verbatim}
data Instruction 
    = Slide Int 
    | Unwind
    | PushGlobal Name 
    | PushInt Int 
    | Push Int 
    | Mkap
    | Pop Int
    | Alloc Int 
    | Update Int
    | Eval
    | Add | Sub | Mul | Div | Neg
    | Eq  | Neq | Lt  | Le | Gt | Ge
    | Cond GmCode GmCode
    | Pack Int Int
    | Casejump [(Int, GmCode)]
    | Split Int
    deriving(Eq, Show)
\end{verbatim}


GmDump represents the dump described in the background section.
It consists of a list of GmDumpItems which contain a tuple of
GmCode and GmStack. When we encounter an expression that 
requires a sub expression to be in weak head normal form, we
defer the current state of GmCode and GmStack to the dump.
We then evaluate the sub expression until it is in WHNF and restore
program flow, where upon we will be able to use the value of the
sub expression in a strictly evaluated context. This is 
comparable to the steps taken to save program state when
calling a subroutine in assembly languages. 

\subsubsection{Compilation Procedure}
Compilation is started with the \emph{compile} function in 
GCompiler.hs. This function takes a Core program and 
returns an initial GmState. The initial values for GmStack..
and GmDump are empty lists. The initial value for GmCode
is [PushGlobal "main", Eval], which will tell the runtime
to start by executing the main supercombinator. We construct 
an initial heap using the buildInitialHeap
function. This calls compileSc on the supercombinator definitions 
present in the input program and in the compiler prelude and combines 
their compiled supercombinators with existing pre-compiled
primitive operations. 

Two compilation schemes exist within the compiler for handling
expressions. The first, represented by the function compileE,
compiles expressions in a strict context. There are cases 
where we know that an expression will need to be evaluated
strictly. An example would be primitive addition. Strictly
compiled expressions generally produce smaller graphs and can
be evaluated quicker. Hence when given the choice, we would
like to evaluate strictly where possible. Expressions which
can be evaluated in this manner are found through pattern
matching in compileE. Those that can't fall through to
compileC, a function representing our lazily compilation
scheme. 

Each super combinator in the program is thus compiled into
a list of instructions by which to instantiate it when it
is called at runtime. These instructions are attached to
NGlobal node data types and added to the heap. Our primitive
operations will also exist in the heap in the same manner.
The sequence of code generated from compiling our program
is now placed in the initial GmCode. GmGlobals is generated
while building the initial heap and will associate the names
of our compiled supercombinators with their addresses in the
heap. We Now have a compiled initial state representing our
program. 

Let's look at our 'K' program after compilation.

\begin{verbatim}
GmCode: [PushGlobal "main", Eval]
GmStack: []
GmDump: []
GmHeap: (2, 
        [3..],  
        [   (2,NGlobal 0 [PushInt 2,PushInt 1,PushGlobal "K",
             Mkap,Mkap,Update 0,Pop 0,Unwind]),
            (1,NGlobal 2 [Push 0,Eval,Update 2,Pop 2,Unwind])
        ])
GmGlobals: [("K",1),("main",2))]

\end{verbatim}

\noindent We can see that the first code to be evaluated at 
runtime will be 
\verb!PushGlobal! \verb!"main"!, \verb!Eval!. 
This will tell our runtime
to instantiate the main supercombinator and provides the entry
point previously mentioned. The stack is empty as expected,
as is the dump. GmHeap contains firstly an integer 2. This 
is the number of objects in the heap; Secondly, a list of
empty addresses (slightly edited for our purposes, the heap 
is represented by an infinite lazy list in Haskell which we
cannot show in its original form for obvious reasons). Lastly,
we have the representation of our compiled graph containing two
NGlobal nodes representing the supercombinators "K" and "main".
The compilation environment has been greatly simplified for
ease of demonstration. Normally all primitive operations 
defined in the compiler as well as any prelude functions would
also be contained in the heap, in a similar fashion to the
two supercombinators above. Lastly, GmGlobals contains the
names and heap addresses of our two supercombinators.

Our initial state is now ready to be evaluated. However, as
it is currently represented in Haskell, we need a way to make
it compatible with JavaScript. 

\subsection{Serialization To JavaScript}
Our serialization code lives in Haskell2JS.hs. It consists of
a number of functions which
translate the components of our state into an equivalent
JavaScript representation. Before showing the operation
of this code, we'll look at the JavaScript implementations
representing the components of our state.

\begin{enumerate}
    \item Lists\\
          We use lists in Haskell to represent globals, the
          heap etc. Haskell equivalent lists do not exist
          in JavaScript, but there is an array type. When 
          we wish to represent a list such as GmGlobals, we
          create a JavaScript array object. GmStack becomes
          \verb!var GmStack = [];!
          GmDump is represented as a list of two-item lists 
          of GmCode and GmStack.
    \item Associative Lists\\
          These are used to represent GmHeap and GmGlobals.
          They consist of a list of tuples. In the case of
          GmHeap for example, we have a list of tuples of
          supercombinator names and heap addresses ([Name,
          Addr]). Primitive JavaScript arrays wont help
          us here, so we use JavaScript objects. The 
          GmGlobals from our compiled state now becomes 

          \begin{verbatim}
            var GmGlobals = {
                "K" : 1,
                "main" : 2
            }
          \end{verbatim}

    \item Data Types \\
          We use Data Types to represent many aspects of 
          our state in Haskell, such as nodes, instructions
          etc. As there is no such concept in JavaScript, 
          we again need to find a new way to represent these
          values. In JavaScript, it is possible to instantiate
          functions as function objects. Function objects are
          similar to regular objects in a number of ways. They
          can be defined in the abstract and instantiated. They
          can take parameters and maintain values as attributes.
          For example, if we wanted to express an NNum node as
          one of these function objects, we could do so like
          this:

          \begin{verbatim}
            function NNum(n){
                this.n = n;
            }
          \end{verbatim}

          We could instantiate this as:

          \begin{verbatim}
            var node = new NNum(n);
          \end{verbatim}

          where n is the value we wish our node to contain, 
          must like the Int parameter passed to the NNum data
          constructor in our Haskell equivalent. 

          We will use this concept of instantiated function
          objects to represent nodes and instructions. In the
          case of data constructors of arity 0, our function
          will take no arguments and appear empty. They are
          still sufficient in this state to represent the
          equivalent data constructors.
\end{enumerate}

Our serialization code will take an initial state from our
compiler and produce an equivalent representation in JavaScript.
This representation will consist of the components described
above. The function GmState2JS in Haskell2JS.hs takes our 
state and calls the relevant functions on its constituent 
parts. Globals, stack and dump are trivial as we know those
will be empty. The heap will require slightly more thought.
GmHeap2JS iterates through each item in the heap, converting
nodes to JavaScript representations. Each node is represented
by an instance of the appropriate function, taking as parameters
the parameters of the node. Converting node parameters is 
trivial in all cases except NGlobal nodes. These will contain
instructions required to instantiate a supercombinator. We
call gmInstruction2JS on these instructions, converting them
also to instantiated function object representations, which
we then include as parameters to the NGlobal node. GmCode
is serialized in a similar manner although in practice that's
trivial as we always know what its contents will be.

The output of this serialization step is a string parse-able
by JavaScript representing our compiled state. For our example
'K' program, that output looks like this:

\begin{verbatim}
    var GmOutput = [];
     
    var GmCode = [new PushGlobal("main"),new Eval()];
     
    var GmStack = [];
     
    var GmDump = [];
     
    var GmHeap = {
        objCount:2,
        freeAddrs:[3,4,5,6,7,8,9,10],
        addrObjMap:{
            2:new NGlobal(0,[new PushInt(2),new PushInt(1),
              new PushGlobal("K"),new Mkap(),new Mkap(),
              new Update(0),new Pop(0),new Unwind()]),
            1:new NGlobal(2,[new Push(0),new Eval(),
              new Update(2),new Pop(2),new Unwind()])}
    };
 
    var GmGlobals = {"K":1,"main":2};
     
    var GmState = [GmOutput, GmCode, GmStack, GmDump, GmHeap, GmGlobals]; 
     
    function main(){
        return evalProg(GmState);
    }
\end{verbatim}

We now have a JavaScript representation of our compiled program
state. The next step is to evaluate this state to a final 
result. This will be accomplish in our runtime, which we will
now describe.

\subsection{Runtime}
We will now examine the implementation of the runtime. As described
in the design choices section, this will be a JavaScript
representation of an abstract machine capable of evaluating 
a Gmachine compiled state. We have already described the 
components of this state and their abstract representations in
JavaScript so this section will be concerned mostly with the
methods of evaluation we employ when executing our state. 

Our runtime consists of a number of stateless functions and the 
global definitions for our compiled state. Functions operating
on our compiled state are generally of the following form:

\begin{verbatim}
    function funcName(xState, otherParams){
        var State = xState;
        var component = getComponent(State);
        alter_component(component);
        var newState = putComponent(State);
    }
\end{verbatim}

\noindent We wish for our runtime operations to be somewhat
pure out of concern for code cleanliness and sanity. However,
JavaScript functions operate on a pass-by-reference basis. 
For this reason, we declare a new variable represented a 
copy of our state inside the scope of each such function.
We apply our changes to scoped copy and return it, leaving
the original copy passed to the function unchanged.

In the serialized example of our "K" function above, you may
have noticed the following function:

\begin{center}
 \verb!main(){return evalProg(GmState)}!
\end{center}

This serves as our browser's entry point to the evaluation of
our state and the JavaScript representation of our Gmachine
evaluator entry point. The call to evalProg() tells our runtime to evaluate
the GmState definition provided. The function evalProg iterates
through each state in the evaluation of our compiled program,
evaluating each in turn until we reach a final state. This
final state is determined by the function gmFinal(), which 
checks if we have run out of instructions to execute in GmCode.
This implies that there is no further evaluation to be performed
on the current state and the node pointed to by the address on
top of the stack should represent the final result of our 
program. 

On each iteration of evalProg()'s evaluation loop, we
call the function step() on the then
current state. Step acts as an instruction dispatch function.
It will pop one instruction from the sequence
in GmCode, check it's value and call the relevant function 
representing its behavior. The instanceof method in JavaScript
is used to check if an instantiated function objects is an
instance of a certain function. This is how we compare our
node and instruction representations and perform pattern 
matching on them. The parameters of each instruction are 
passed as parameters to the functions representing their
behavior. 

We will now examine some of the utility functions in our
runtime. Between lines 66 and 91 of runtime.js, we have
functions \verb!id()!, \verb!head()!, \verb!tail()! and an array prototype
method addition \verb!drop()!. The first three functions work
as expected. Functions \verb!head()! and \verb!tail()! are included to
make reasoning on lists more intuitive. JavaScript has
built in push and pop methods, however these operate in
a destructive pass-by-reference sense which is unhelpful
when trying to model execution avoiding the notion of
global state. \verb!drop()! was included for similar reasons, 
implementing similar functionality to Haskell's drop.
In a sense, we could say that the implementation of the
runtime is somewhat functionally inspired. We have avoided
using globally stateful computations and implemented
common functional methods such as \verb!head()! and 
\verb!tail! to allow for easy reasoning on lists. There is
no particular significance in this beyond making our
runtime easier to implement and reason about.

\verb!hAlloc! at line 233 is used to allocate a node on the
heap. It takes the GmHeap from our state and a node
and returns a new heap with the node at the last free
address of the heap. The free addresses and object
count of the returned heap reflect this change. 
hLookup and aLookup immediately following are used 
to lookup items in the heap and globals respectively. 
Lines 255 to 320 contain a number of similar looking 
functions. These are used to standardize access to 
components of our heap, making it easier to access and
update our state in a clean and organized fashion.

\subsubsection{Runtime Instructions}
The following provides a description of the implementation
of our instructions and the the functions which execute their
behavior in our runtime. In general, the functions representing
the actions of instructions are named for their namesake. They
all take as parameters a program state and any parameters
required by the instruction. They all return a program state.
The code related to this section is included in appendix A.

pushglobal() takes the name of a super combinator. It finds 
the address of the super combinator by name in the globals 
array of the state and pushes this onto the stack of the returned
state.

pushint() takes a literal integer and allocates an NNum node
in the heap to represent it. The address of the new node is
pushed onto the stack of the returned state.

mkap() takes no additional parameters. It pops the top two 
addresses from the stack of the state passed to it. A new
NAp node is created with these two addresses as parameters
and is inserted into the heap. The address of the new node
is pushed to the stack and both it and the updated heap
are returned in a new state. 

push() takes an integer representing an index in the stack.
The address located at this index is pushed to the top of
a stack which is returned in a new state.

pack() is used to create NConstr nodes, representing data
constructors in our heap. The function takes two integer
as additional parameters, a tag and an arity respectively.
We assume as many elements of the data constructor as 
indicated by the arity parameter are addressed by the top
items on the stack. We pop these from the stack and use
them along with the tag to create an NConstr node, which 
we insert into the heap. The new heap and stack are 
returned in a new state.

casejump() takes as an additional argument an associative
array of integers and code sequences. The integers represent
tags in data constructors. The code sequences contain the 
sequences of instructions to undertake if the associated tag
is encountered. The function expects to find a constructor
tag address on top of the stack. The node pointed to by the
top address is found in the heap and its tag extracted. The
code sequence associated with that tag is located in the array
and is added to the existing code sequence in the program
state. This new code sequence is returned in a new state.

split() takes as an additional argument an integer N. Split
instructions are encountered at the start of each case 
alternative in a case statement. The function itself finds
the NConstr node pointed to by the address on top of the
stack and replace this address with the addresses of each
of the elements in of the data constructor. We can then
access the tags of these elements in a casejump. A Slide
instruction following the case alternative will then remove
these addresses from the stack. 

update() is used to overwrite the root of a reducible expression
with its value after it is first evaluated. This corresponds
with the typical update operation describe in the background
section. The function takes an integer N as an additional
parameter. It will 

pop() takes an integer N and pops N items from the stack.
The resultant stack is returned in a new state.

evalInst() corresponds to the Eval instruction but is so named
because of naming conflicts with JavaScript's built-in eval
method and another similarly named function in our runtime.
Eval is used to evaluate an expression to weak head normal
form, at least in theory. In practice, it defers the current
stack and code state to the dump and replaces them with a
single pointer to the expression to be evaluated and a single
Unwind instruction. These are returned in a new state.

The next two functions handle boxing and unboxing of integers
in NNum nodes. boxInteger() takes a value N and creates an
NNum node representing this value. This is added to the heap
and its address added to the front of the stack. unboxInteger()
takes the address of an integer node, finds it in the stack
and returns the integer value it contains. 

boxBoolean() takes a boolean value and converts it to an
integer representation. There is no boolean node representation
in our compiler which is fine as one isn't needed. The function
creates an NConster of tag 1 to represent true, 2 to represent 
false and adds it to the heap. The address is pushed to the
front of the stack and both are returned in a new state.

Functions primitive1() and primitive2() are used to simplify
arithmetic operations. They handle the application of monadic
and dyadic operators respectively. Both accept as parameters:

\begin{enumerate}
    \item A boxing function, to place values in nodes and
          add them to the heap.
    \item An unboxing function to extract values from nodes.
    \item The operator in question to apply.
    \item The current state
\end{enumerate}

\noindent using these functions greatly minimizes the code we
need to write for the functions representing our arithmetic and
equality checking instructions. A number of such primitives
are implemented in the runtime, all with much the same format;
functions that take a state, call the relevant arity primitive 
handling function and pass to it a function representing the 
JavaScript operator we wish to use. 

A function cond() handles conditionals. This takes two instruction
sequences as well as the usual state and expects to find the address
of an NConstr node on top of the stack. This node is found in the
heap and its tag checked. As with boxBoolean(), a tag of 1 represents
true, 2 false. Based on the tag, the appropriate of the two instruction
sequences passed as parameters if added to the current code sequence
and returned in a new state.

Lastly, the unwind() function is used to unwind the spine of the
expression currently being evaluated. The unwind() function checks
the type of the node on top of the stack using a series of if
statements. Again, instanceof is used to determine the function
from which the node was instantiated. The exact actions of unwind()
will vary depending on the type of the node found but the general
aim is to leave a pointer to a normalized expression on top of
the stack. 

\begin{itemize}

\item If an indirection is encountered it is replaced with the
expression pointer it contains and another Unwind is added to the
instruction sequence. 

\item If an application is found, both of its
arguments are added to the stack and another Unwind is added. 

\item If
an NNum node pointer is found, and there is no state currently
stored in the dump, we return the current state as there is nothing
to change. If the dump is not empty we pop the top code/stack pair
from the dump, replace the current code sequence with the restored
code sequence and append the restored stack to the current stack. 
This signifies that we just finished evaluating an expression to
WHNF and are now ready to return to regular evaluation.

\item If the top stack item points to an NConster we do the same
as in the case of NNum nodes for the same reasons.

\item If the top stack item is a pointer to an NGlobal node 
then we add its code the code sequence so that it can be evaluated.
We can see this as being the implementation of a function call.

\end{itemize}

\subsubsection{Example Evaluation}
We will now provide an example of program evaluation in our runtime.
As before, we will use our "K" program. For brevity's sake, we will
describe the states we encounter informally or in Haskell as their
JavaScript representations are less readable. When last we saw our
program it consisted of an empty stack and dump, a heap and globals
array containing 2 items each, and a code sequence of PushGlobal
main, Eval. We start by calling the main function which in turn
calls evalProg on our initial state. We then iterate through each
state.

\begin{itemize}
    \item Iteration 1: PushGlobal instruction encountered, find
          address of "main" super combinator passed as argument
          and add to stack. 
    \item Iteration 2: Eval function encountered. Defer state of
          stack and code sequence to dump. Code is empty and stack
          contains only the address of "main" so dump is updated
          to [([],[])]. Unwind instruction added to code sequence.
    \item Iteration 3: Unwind finds pointer to WHNF super combinator
          "main" and places its code sequence in GmCode.
    \item Iterations 4, 5: "K" is being called on integers 1 and 2.
          PushInt 1 and 2 add the appropriate nodes to the heap and
          their addresses to the top of the stack. Globals also
          updated.
    \item Iterations 6 - 8: Address of super combinator "K" pushed
          to stack. Two subsequent Mkap instructions add two NAp
          nodes creating a graph of "K", 1 and 2. 
    \item Iteration 9,10: Update 0 instruction creates NInd
          indirection node to heap node 6. Pop 0 pops no addresses
          from the stack. Both trivial operations in this particular
          example.
    \item Iterations 10 - 13: Series of Unwind instructions. Firstly
          redirects trivial NInd node by replacing its address on the
          stack with that of its pointer (address 6). Places left
          arguments of both Mkap nodes on top of stack. When Unwind
          encounters pointer to "K" on stack, its code is added to
          the code sequence.
    \item Iteration 14: Push 0 instruction at head of code sequence
          pushes pointer to first argument to "K" onto stack. This
          is the actual behaviour of "K".
    \item Iterations 15 - 20: Eval instruction following "K" checks
          the return argument is in WHNF as before. Update 2 instruction
          overwrites the poitner to "K" with the value of its evaluation.
          Pop 2 instruction removes the argument pointers passed to
          "K" from the stack. Series of Unwind instructions follows,
          until we are left with a pointer to a single WHNF node on
          top of the stack.
    \item Iteration 21: Pointer to NNum 1 on top of stack. No further
          code to evaluate. Final state.
\end{itemize}

At this point, the GmCode part of our starting GmState is empty.
GmHeap will contain a number of additional nodes compared to its
starting state as we added nodes representing the parameters passed
to our K function, applicator nodes to form a reducible graph 
expression and indirection nodes to aid in updating. GmStack will
contain a single item pointing to the return value of evaluating
our program, in this case an NNum node of value 1. This value will
be extracted and returned by evalProg().

\subsection{Specific Feature Implementations}
When we encounter a dyadic expression application in our input
program, we check if the expression being applied is a built-in
primitive defined in our compiler. If so, we know that we are
compiling in a strict context. We compile the arguments to the
operator in this same context and place the instruction 
representing our primitive operation after the compiled arguments
in the code sequence. If the application is not recognized, we
assume it is a user (or possibly prelude) defined supercombinator
and compile it in a lazy context. This will result in a code
sequence containing a Mkap instruction to construction an application
node in the graph the arguments to the application, compiled in the
same context. With one exception there are no non-dyadic operations
defined in our compiler, so non-dyadic expression applications
will default to the lazy compilation scheme. The exception is
the negate function, a unary primitive operation.

Data constructors are represented using EConstr expressions in 
the abstract data type of our input language. These are treated
as applicable expressions in the compiler, not unlike super 
combinators or primitive operations. When we encounter an 
application, we first check if the expression we are applying
is an EConstr. This is done by recursively checking its arguments
for the presence of an EConstr. If so, we compile its arguments 
and follow them in the emitted code sequence with a Pack t n 
instructions, where t will be the tag of the constructor and n 
its arity. It is presumed that the previous n items in the code 
sequence will be its arguments. 

Case expressions are represented in the input language as ECase
expressions, which take an expression and a series of case 
alternatives. The expression will evaluate to a data constructor
whose tag will correspond to one of the case alternatives. The 
expression will be compiled ahead of the alternatives and its
evaluated result placed on the stack. When the casejump instruction 
is encountered in the runtime, the data constructor will be 
found in the heap and the code from the compiled case alternative
corresponding to its tag placed in the code sequence.


\subsection{Others}
There are a few other aspects of the implementation that
are probably worth mentioning. A prelude for the compiler exists
in GPrelude.hs. This would normally contain a list of prelude
definitions but for testing purposes it currently contains a 
number of test program definitions. This would be useful for
anyone looking to test the compiler.  An evaluator written in 
Haskell exists in GEval.hs. This was written concurrently with 
the runtime, as it helped greatly in diagnosing errors which 
were somewhat vague in JavaScript. Lastly, in order to actually
use the compiler, catalyst.hs provides a command line interface.
It can be ran from the Linux command line with the -h flag which
will return some helpful information and further instructions.






















